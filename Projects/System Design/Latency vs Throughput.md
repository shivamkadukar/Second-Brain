[Latency vs Throughput](https://cs.fyi/guide/latency-vs-throughput)
[Understanding Latency versus Throughput](https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput)

Latency refers to the amount of time it takes for a system to respond to a request. It is often measured in milliseconds or microseconds.
Time required to perform some action or to produce some result.
_Low Latency --> faster and responsive system_

Latency can be caused by various factors e.g., network i.e. time it takes for data to travel through the network (more hops, high latency), network congestion, inefficient algorithms, load on the resources and so on.

Throughput refers to the number of requests that a system can handle at the same time or the number of units of data that can be processed in a given period of time. Throughput is often measured in requests per second, transactions per second, or bits per second.
The number of such actions executed or results produced per unit of time.
_High Throughput --> more responsive systems and more efficient use of resources_

Ideal -- _Low Latency and High Throughput_
Aim for -- _Maximal Throughput and acceptable latency_






